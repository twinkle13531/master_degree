{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dwave-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "import math\n",
    "from neal import SimulatedAnnealingSampler\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dwave.system.samplers import DWaveCliqueSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "from dwave.embedding.chain_strength import uniform_torque_compensation\n",
    "import dimod\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_marginals(df):                   \n",
    "    return np.array([                      \n",
    "        sum(df['Y']),                     \n",
    "        np.dot(df['Y'], df['LI']),      \n",
    "        np.dot(df['Y'], df['SEX']),      \n",
    "        np.dot(df['Y'], df['AOP']),      \n",
    "    ])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Hamiltonian(df, t1):\n",
    "    t_list = calc_marginals(df)\n",
    "    N=len(df)\n",
    "    dup_list = [(i, i) for i in range(N)]\n",
    "    comb_list = [(i, j) for i in range(N) for j in range(i+1, N)]\n",
    "    \n",
    "    lin_Y = [1-2*t_list[0] for (i, _) in dup_list] #同じy同士\n",
    "    quad_Y = [2 for (i, j) in comb_list] #異なるy同士\n",
    "    num_Y = t_list[0]**2 #数字の二乗\n",
    "    \n",
    "    LI = df['LI'].iloc\n",
    "    lin_LI = [(LI[i] - 2 * t1) * LI[i] for (i, _) in dup_list]\n",
    "    quad_LI = [2*LI[i] * LI[j] for (i, j) in comb_list]\n",
    "    num_LI = t1**2\n",
    "    \n",
    "    SEX = df['SEX'].iloc\n",
    "    lin_SEX  = [(SEX[i] - 2 * t_list[2]) * SEX[i] for (i, _) in dup_list]\n",
    "    quad_SEX  = [2*SEX[i] * SEX[j] for (i, j) in comb_list]\n",
    "    num_SEX  = t_list[2]**2\n",
    "    \n",
    "    AOP = df['AOP'].iloc\n",
    "    lin_AOP = [(AOP[i] - 2 * t_list[3]) * AOP[i] for (i, _) in dup_list]\n",
    "    quad_AOP = [2*AOP[i] * AOP[j] for (i, j) in comb_list]\n",
    "    num_AOP = t_list[3]**2\n",
    "    \n",
    "    #lin\n",
    "    lin_list = [sum(lin) for lin in zip(lin_Y, lin_LI, lin_SEX, lin_AOP)]\n",
    "    lin = {i: lin_list[i] for (i, _) in dup_list}\n",
    "    \n",
    "    #quad\n",
    "    quad_values = [sum(quad) for quad in zip(quad_Y, quad_LI, quad_SEX, quad_AOP)]\n",
    "    quad = {ij: quad_values[n] for (n, ij) in enumerate(comb_list)}\n",
    "    \n",
    "    #num\n",
    "    num = num_Y + num_LI + num_SEX + num_AOP\n",
    "    \n",
    "    #print('lin:', lin)\n",
    "    #print('quad:', quad)\n",
    "    #print('num:', num)\n",
    "    return dimod.BinaryQuadraticModel(lin, quad, num, dimod.Vartype.BINARY)#dic, dic, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_y_1(df, num_reads):                                                        \n",
    "    DWAVE_TOKEN=\"TOKY-1319d5c52b9aa35f34b40feba0cea58a4f5d3c09\"\n",
    "    \n",
    "    # dimod sampler\n",
    "    dw_sampler = DWaveCliqueSampler(\n",
    "        endpoint=\"https://cloud.dwavesys.com/sapi\",\n",
    "        solver = 'DW_2000Q_6',\n",
    "        token = DWAVE_TOKEN\n",
    "    )\n",
    "    \n",
    "    # インスタンス作成\n",
    "    qa_sampler = EmbeddingComposite(dw_sampler)\n",
    "    \n",
    "    t_list = calc_marginals(df)\n",
    "    valid_y_list = {}                                                                   \n",
    "    valid_y_num = {}\n",
    "    \n",
    "    for t1 in range(0, sum(df['LI'])+1):                                                                                                                                                                                                                                               \n",
    "        bqm = make_Hamiltonian(df, t1)\n",
    "        \n",
    "        res = qa_sampler.sample(bqm, chain_break_fraction=True, num_reads=num_reads)\n",
    "        \n",
    "        valid_y_list[t1] = []                                                           \n",
    "        valid_y_num[t1] = 0                                                             \n",
    "        for y_info in list(res.record):\n",
    "            #print(y_info)\n",
    "            if y_info[1] == 0.:\n",
    "                valid_y_num[t1] += 1                                        \n",
    "                valid_y_list[t1].append(list(y_info[0]))                    \n",
    "                #print('energy0')\n",
    "                                                      \n",
    "    return valid_y_list, valid_y_num       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_y_2(df, num_reads):                                                        \n",
    "    DWAVE_TOKEN=\"TOKY-1319d5c52b9aa35f34b40feba0cea58a4f5d3c09\"\n",
    "    \n",
    "    # dimod sampler\n",
    "    dw_sampler = DWaveCliqueSampler(\n",
    "        endpoint=\"https://cloud.dwavesys.com/sapi\",\n",
    "        solver = 'DW_2000Q_6',\n",
    "        token = DWAVE_TOKEN\n",
    "    )\n",
    "    \n",
    "    # インスタンス作成\n",
    "    qa_sampler = EmbeddingComposite(dw_sampler)\n",
    "    \n",
    "    t_list = calc_marginals(df)\n",
    "    valid_y_list = {}                                                                   \n",
    "    valid_y_num = {}\n",
    "    \n",
    "    for t1 in range(0, sum(df['LI'])+1):                                                                                                                                                                                                                                               \n",
    "        bqm = make_Hamiltonian(df, t1)\n",
    "        \n",
    "        res = qa_sampler.sample(bqm, chain_break_fraction=False, num_reads=num_reads)\n",
    "        \n",
    "        valid_y_list[t1] = []                                                           \n",
    "        valid_y_num[t1] = 0                                                             \n",
    "        for y_info in list(res.record):\n",
    "            #print(y_info)\n",
    "            if y_info[1] == 0.:\n",
    "                valid_y_num[t1] += 1                                        \n",
    "                valid_y_list[t1].append(list(y_info[0]))                    \n",
    "                #print('energy0')\n",
    "                                                      \n",
    "    return valid_y_list, valid_y_num       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_y_3(df, num_reads):                                                        \n",
    "    DWAVE_TOKEN=\"TOKY-1319d5c52b9aa35f34b40feba0cea58a4f5d3c09\"\n",
    "    \n",
    "    # dimod sampler\n",
    "    dw_sampler = DWaveCliqueSampler(\n",
    "        endpoint=\"https://cloud.dwavesys.com/sapi\",\n",
    "        solver = 'DW_2000Q_6',\n",
    "        token = DWAVE_TOKEN\n",
    "    )\n",
    "    \n",
    "    # インスタンス作成\n",
    "    qa_sampler = EmbeddingComposite(dw_sampler)\n",
    "    \n",
    "    t_list = calc_marginals(df)\n",
    "    valid_y_list = {}                                                                   \n",
    "    valid_y_num = {}\n",
    "    \n",
    "    t1 = 6\n",
    "    bqm = make_Hamiltonian(df, t1)\n",
    "\n",
    "    for chain_strength in range(0, 100):\n",
    "        res = qa_sampler.sample(bqm, chain_strength = chain_strength, chain_break_fraction=True, num_reads=num_reads)\n",
    "\n",
    "        valid_y_list[chain_strength] = []                                                           \n",
    "        valid_y_num[chain_strength] = 0                                                             \n",
    "        for y_info in list(res.record):\n",
    "            if y_info[1] == 0.:\n",
    "                valid_y_num[chain_strength] += 1                                        \n",
    "                valid_y_list[chain_strength].append(list(y_info[0]))\n",
    "                                                      \n",
    "    return valid_y_list, valid_y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../input/ost16.csv', sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_marginals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no structured sampler found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5352b3180292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_reads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfind_valid_y_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_reads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#embedding >> Autoembedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-2bfacd22abc0>\u001b[0m in \u001b[0;36mfind_valid_y_1\u001b[0;34m(df, num_reads)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# インスタンス作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mqa_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingComposite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mt_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_marginals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/dwave/system/composites/embedding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, child_sampler, find_embedding, embedding_parameters, scale_aware, child_structure_search)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# searches but since (as of 14 june 2019) all composites have single\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# children, just doing dfs seems safe for now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_structure_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_sampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_aware\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_aware\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/dimod/utilities.py\u001b[0m in \u001b[0;36mchild_structure_dfs\u001b[0;34m(sampler, seen)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no structured sampler found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no structured sampler found"
     ]
    }
   ],
   "source": [
    "num_reads = 100\n",
    "find_valid_y_1(df, num_reads)#embedding >> Autoembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: [],\n",
       "  1: [],\n",
       "  2: [],\n",
       "  3: [],\n",
       "  4: [],\n",
       "  5: [],\n",
       "  6: [],\n",
       "  7: [],\n",
       "  8: [],\n",
       "  9: [],\n",
       "  10: [],\n",
       "  11: [],\n",
       "  12: [],\n",
       "  13: [],\n",
       "  14: []},\n",
       " {0: 0,\n",
       "  1: 0,\n",
       "  2: 0,\n",
       "  3: 0,\n",
       "  4: 0,\n",
       "  5: 0,\n",
       "  6: 0,\n",
       "  7: 0,\n",
       "  8: 0,\n",
       "  9: 0,\n",
       "  10: 0,\n",
       "  11: 0,\n",
       "  12: 0,\n",
       "  13: 0,\n",
       "  14: 0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_reads = 100\n",
    "find_valid_y_2(df, num_reads)#chain_break_fractionはtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 100\n",
    "find_valid_y_3(df, num_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1]\n",
      "[2 2 1 2]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-29187be6e091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_list2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_list1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt_list2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-29187be6e091>\u001b[0m in \u001b[0;36mtest_validity\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_list1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_list2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_list1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt_list2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_validity():\n",
    "    df1 = pd.read_csv('../../input/ost6.csv', sep=',',index_col=0)\n",
    "    df2 = pd.read_csv('../../input/ost6.csv', sep=',',index_col=0)\n",
    "    new_y = np.array([0, 1, 0, 0, 0, 1])\n",
    "    df2['Y'] = new_y\n",
    "    t_list1 = calc_marginals(df1)\n",
    "    t_list2 = calc_marginals(df2)\n",
    "    print(t_list1)\n",
    "    print(t_list2)\n",
    "    assert np.all(t_list1[[0,2,3]] == t_list2[[0,2,3]]) \n",
    "test_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measurement(df):\n",
    "    sum_time = 0\n",
    "    annealing_time = 20\n",
    "    for t1 in range(0, sum(df['LI'])+1):\n",
    "        timeit_repeat = timeit.repeat(\"make_Hamiltonian(df, t1)\", number=1, repeat=1, globals={\"make_Hamiltonian\": make_Hamiltonian, \"df\": df, \"t1\": t1})\n",
    "        sum_time += timeit_repeat[0] + annealing_time\n",
    "    return sum_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [], 1: [], 2: [[1, 0, 0, 0, 0, 1], [1, 0, 0, 0, 1, 0]], 3: [], 4: [], 5: [], 6: []} {0: 0, 1: 0, 2: 2, 3: 0, 4: 0, 5: 0, 6: 0}\n"
     ]
    }
   ],
   "source": [
    "#==========\n",
    "#テストコード\n",
    "#==========\n",
    "def test_find_valid_y():\n",
    "    df = pd.read_csv('../../input/ost6.csv', sep=',', index_col=0)\n",
    "    true_t1 = sum(df['Y'] * df['LI'])\n",
    "    valid_y_list, valid_y_num = find_valid_y(df,  num_reads=20)\n",
    "    print(valid_y_list, valid_y_num)\n",
    "    assert valid_y_num[true_t1] > 0\n",
    "    \n",
    "test_find_valid_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1]\n",
      "[2 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "def test_validity():\n",
    "    df1 = pd.read_csv('../../input/ost6.csv', sep=',',index_col=0)\n",
    "    df2 = pd.read_csv('../../input/ost6.csv', sep=',',index_col=0)\n",
    "    new_y = np.array([1, 0, 0, 0, 0, 1])\n",
    "    df2['Y'] = new_y\n",
    "    t_list1 = calc_marginals(df1)\n",
    "    t_list2 = calc_marginals(df2)\n",
    "    print(t_list1)\n",
    "    print(t_list2)\n",
    "    assert np.all(t_list1[[0,2,3]] == t_list2[[0,2,3]]) \n",
    "\n",
    "#test_validity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
