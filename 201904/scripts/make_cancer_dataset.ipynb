{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import Augmentor\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "\n",
    "# https://github.com/mdbloice/Augmentor\n",
    "# pip install Augmentor\n",
    "# 機械学習用にイメージデータを水増しするライブラリ\n",
    "\n",
    "# 再帰フォルダ探索のPATH格納\n",
    "IMG_LIST_PATH = []\n",
    "# 増やしたい画像枚数\n",
    "TEST_DATA_NUM = 1000\n",
    "\n",
    "\n",
    "def augment_data(img_dic):\n",
    "    # Augmentorの処理\n",
    "    for path, num in img_dic.items():\n",
    "        make_test_img_num = TEST_DATA_NUM - num\n",
    "\n",
    "        # 画像フォルダ\n",
    "        p = Augmentor.Pipeline(path)\n",
    "\n",
    "        # キャンバスの歪み\n",
    "        p.skew_tilt(probability=0.3, magnitude=0.5)\n",
    "\n",
    "        # 中心の歪み\n",
    "        p.random_distortion(probability=0.3, grid_width=2, grid_height=2, magnitude=2)\n",
    "\n",
    "        # 回転\n",
    "        p.rotate90(probability=0.3)\n",
    "        p.rotate270(probability=0.3)\n",
    "        p.rotate(probability=0.3, max_left_rotation=10, max_right_rotation=10)\n",
    "\n",
    "        # 反転\n",
    "        p.flip_left_right(probability=0.3)\n",
    "        p.flip_top_bottom(probability=0.3)\n",
    "\n",
    "        # ずらし\n",
    "        p.crop_random(probability=1, percentage_area=0.3)\n",
    "\n",
    "        p.resize(probability=1.0, width=64, height=64)\n",
    "        p.sample(make_test_img_num)\n",
    "\n",
    "\n",
    "def traverse_dir(path):\n",
    "    for file_or_dir in os.listdir(path):\n",
    "        abs_path = os.path.abspath(os.path.join(path, file_or_dir))\n",
    "        if os.path.isdir(abs_path):\n",
    "            traverse_dir(abs_path)\n",
    "        else:\n",
    "            # 画像を見つけたら、親フォルダのPathを格納しておく\n",
    "            img_directory = os.path.dirname(abs_path)\n",
    "            if img_directory not in IMG_LIST_PATH:\n",
    "                IMG_LIST_PATH.append(img_directory)\n",
    "\n",
    "\n",
    "def get_folder_list(path):\n",
    "    global IMG_LIST_PATH\n",
    "\n",
    "    # 再帰でフォルダ内のDatasetを取得\n",
    "    traverse_dir(path)\n",
    "    imglist_num = {}\n",
    "    # DatasetのFolderPathと、Folder内の画像数をDictionaryに入れておく\n",
    "    for path in IMG_LIST_PATH:\n",
    "        imglist_num[path] = len(os.listdir(path))\n",
    "\n",
    "    IMG_LIST_PATH = {}\n",
    "    return imglist_num\n",
    "\n",
    "\n",
    "def copy_original_data(imgs_dic):\n",
    "    for path in imgs_dic.keys():\n",
    "        # Augmentorの処理まち\n",
    "        while True:\n",
    "            check_foleder = os.path.join(path, \"output\")\n",
    "            if os.path.exists(check_foleder):\n",
    "                time.sleep(1)\n",
    "                break\n",
    "\n",
    "        # label直下に持ってくる\n",
    "        test_data_path = os.path.join(path, \"output\")\n",
    "        for file_or_dir in os.listdir(test_data_path):\n",
    "            abs_path = os.path.abspath(os.path.join(test_data_path, file_or_dir))\n",
    "            if os.path.isdir(abs_path):\n",
    "                pass\n",
    "            else:\n",
    "                dest_path= os.path.join(path, file_or_dir)\n",
    "                shutil.move(abs_path, dest_path)\n",
    "\n",
    "        del_folder = os.path.join(path, \"output\")\n",
    "        shutil.rmtree(del_folder)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 一括でAugmentorを行いたいFolderを指定する\n",
    "    target_path = \"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_images\"\n",
    "\n",
    "    # 上記指定フォルダ配下のフォルダに存在するもの全部を取得\n",
    "    imgs_dic = get_folder_list(target_path)\n",
    "    # Augumentorを一括で実施\n",
    "    augment_data(imgs_dic)\n",
    "    # Augmentorがoutput folderを作るので、同一フォルダにコピーしてくる\n",
    "    copy_original_data(imgs_dic)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各画像typeごとにディレクトリを作成し、画像データを格納した後👇\n",
    "\n",
    "#撮影したデータについてラベリング（画像データと商品名の紐付け）を実施し、学習/検証データを用意する、というコード\n",
    "\n",
    "\n",
    "#ラベリングによる学習/検証データの準備\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import random, math\n",
    "\n",
    "#画像が保存されているルートディレクトリのパス\n",
    "root_dir  = \"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_images/\" #MacとWindowsでは違うので書き換えを\n",
    "# がん細胞の種類\n",
    "categories = [\"type0\", \"type1\", \"type2\", \"type3\", \"type4\", \"type5\", \"typeB\"]\n",
    "\n",
    "# 画像データ用配列\n",
    "X = []\n",
    "# ラベルデータ用配列\n",
    "Y = []\n",
    "\n",
    "#画像データごとにadd_sample()を呼び出し、X,Yの配列を返す関数\n",
    "def make_sample(files):\n",
    "    global X, Y\n",
    "    X = []\n",
    "    Y = []\n",
    "    for cat, fname in files:\n",
    "        add_sample(cat, fname)\n",
    "    return np.array(X), np.array(Y) #Numpy配列\n",
    "\n",
    "#渡された画像データを読み込んでXに格納し、また、\n",
    "#画像データに対応するcategoriesのidxをY格納する関数\n",
    "def add_sample(cat, fname):\n",
    "    img = Image.open(fname)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((70, 70))\n",
    "    data = np.asarray(img)\n",
    "    X.append(data)\n",
    "    Y.append(cat)\n",
    "\n",
    "#全データ格納用配列\n",
    "allfiles = []\n",
    "\n",
    "#カテゴリ配列の各値と、それに対応するidxを認識し、全データをallfilesにまとめる\n",
    "for idx, cat in enumerate(categories):\n",
    "    image_dir = root_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir + \"/*.tiff\") #拡張子check\n",
    "    for f in files:\n",
    "        allfiles.append((idx, f))\n",
    "\n",
    "#シャッフル後、学習データと検証データに分ける\n",
    "random.shuffle(allfiles)\n",
    "th = math.floor(len(allfiles) * 0.8)\n",
    "train = allfiles[0:th]\n",
    "test  = allfiles[th:]\n",
    "X_train, y_train = make_sample(train)\n",
    "X_test, y_test = make_sample(test)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "#データを保存する\n",
    "np.save(\"cancercells_npdata\", xy) #cancercells_npdata.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの構築\n",
    "\n",
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape=(70,70,3))) #一番上のcellにある\"img = img.resize((150, 150))\"と揃える\n",
    "model.add(layers.MaxPooling2D((2,2))) #MaxPooling2D layer...プーリング層\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\")) #Conv2D layer...畳み込み層\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten()) #後に多層パーセプトロンに入力するときはデータをフラット化する必要がある。\n",
    "#4次元配列を1次元配列に変換するにはFlatten()という層を追加するだけでOK。ユニット数などは自動的に計算してくれる。\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512,activation=\"relu\")) #Dense layer...全結合層\n",
    "model.add(layers.Dense(7,activation=\"sigmoid\")) #分類先の種類分設定(今回7分類なので7とする） #出力数\n",
    "\n",
    "#モデル構成の確認\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルのコンパイル\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先ほど作成した学習/検証データを読み込み、データの正規化といった学習に向けた準備をする\n",
    "\n",
    "#データの準備\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "categories = [\"type0\", \"type1\", \"type2\", \"type3\", \"type4\", \"type5\", \"typeB\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load(\"cancercells_npdata.npy\")\n",
    "\n",
    "#データの正規化\n",
    "X_train = X_train.astype(\"float\") / 255\n",
    "X_test  = X_test.astype(\"float\")  / 255\n",
    "\n",
    "#kerasで扱えるようにcategoriesをベクトルに変換\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test  = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの学習\n",
    "model = model.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=10,\n",
    "                  batch_size=128,\n",
    "                  validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習結果を表示\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = model.history['acc']\n",
    "val_acc = model.history['val_acc']\n",
    "loss = model.history['loss']\n",
    "val_loss = model.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('cancerimages_accuracy6') #毎回番号変えて保存\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('cancerimages_loss6') #毎回番号変えて保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの保存\n",
    "\n",
    "json_string = model.model.to_json()\n",
    "open('/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/canerimages_predict.json', 'w').write(json_string)\n",
    "\n",
    "#重みの保存\n",
    "\n",
    "hdf5_file = \"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancerimages_predict.hdf5\"\n",
    "model.model.save_weights(hdf5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータの作成\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import random, math\n",
    "\n",
    "# 画像が保存されているディレクトリのパス\n",
    "root_dir = \"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_images\"\n",
    "# 画像が保存されているフォルダ名\n",
    "categories = [\"type0\", \"type1\", \"type2\", \"type3\", \"type4\", \"type5\", \"typeB\"]\n",
    "\n",
    "X = [] # 画像データ\n",
    "Y = [] # ラベルデータ\n",
    "\n",
    "# フォルダごとに分けられたファイルを収集\n",
    "#（categoriesのidxと、画像のファイルパスが紐づいたリストを生成）\n",
    "allfiles = []\n",
    "for idx, cat in enumerate(categories):\n",
    "    image_dir = root_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir + \"/*.tiff\")\n",
    "    for f in files:\n",
    "        allfiles.append((idx, f))\n",
    "\n",
    "for cat, fname in allfiles:\n",
    "    img = Image.open(fname)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((70, 70))\n",
    "    data = np.asarray(img)\n",
    "    X.append(data)\n",
    "    Y.append(cat)\n",
    "\n",
    "x = np.array(X)\n",
    "y = np.array(Y)\n",
    "\n",
    "np.save(\"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_data_test/cancer_data_test_X_150\", x)\n",
    "np.save(\"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_data_test/cancer_data_test_Y_150\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モデルの精度を測る\n",
    "\n",
    "#評価用のデータの読み込み\n",
    "eval_X = np.load(\"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_data_test/cancer_data_test_X_150.npy\")\n",
    "eval_Y = np.load(\"/Users/shihosato/OneDrive/programming/tsuda_lab/cancer_cells/cancer_data_test/cancer_data_test_Y_150.npy\")\n",
    "\n",
    "#Yのデータをone-hotに変換\n",
    "from keras.utils import np_utils\n",
    "\n",
    "eval_Y = np_utils.to_categorical(eval_Y, 7)\n",
    "\n",
    "score = model.model.evaluate(x=eval_X, y=eval_Y)\n",
    "\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果\n",
    "\n",
    "#### そのまま\n",
    "* accuracy=0.87ぐらい（記録忘れ）\n",
    "\n",
    "#### Dropout0.5, Augmentorで1000画像/1カテゴリに\n",
    "* 6987/6987  - 38s 5ms/step  \n",
    "* loss= 3.289973085592348  \n",
    "* accuracy= 0.788239433356957\n",
    "* plt.savefig('cancerimages_accuracy')（以降.1, .2,,,として保存した）\n",
    "* plt.savefig('cancerimages_loss')（同上）\n",
    "\n",
    "#### img = img.resize((150, 150))→((250, 250))（1）\n",
    "* validationすら0.85程度であったため中止\n",
    "\n",
    "#### batch_size=6→32（2）\n",
    "* Epoch 1/10 5589/5589 - 257s 46ms/step - loss: 0.4092 - acc: 0.8554 - val_loss: 0.3811 - val_acc: 0.8568\n",
    "* Epoch 10/10 5589/5589- 233s 42ms/step - loss: 0.3190 - acc: 0.8680 - val_loss: 0.3892 - val_acc: 0.8414（学習回数重ねたのに下がっている）\n",
    "* 6987/6987 - 101s 14ms/step\n",
    "* loss= 3.879581622053186\n",
    "* accuracy= 0.7531743155062173\n",
    "\n",
    "####  img = img.resize((100, 100)) (上書き保存したため無くなった）\n",
    "* Epoch 1/10 5589/5589 - 48s 9ms/step - loss: 0.4210 - acc: 0.8550 - val_loss: 0.3968 - val_acc: 0.8571\n",
    "* Epoch 10/10 5589/5589 - 47s 8ms/step - loss: 0.3523 - acc: 0.8589 - val_loss: 0.3451 - val_acc: 0.8623\n",
    "* 6987/6987 - 20s 3ms/step\n",
    "* loss= 3.1761112101893234\n",
    "* accuracy= 0.7909383186543979\n",
    "\n",
    "#### batch_size=64（3）\n",
    "* Epoch 1/10 5589/5589 - 41s 7ms/step - loss: 0.4333 - acc: 0.8525 - val_loss: 0.4168 - val_acc: 0.8571\n",
    "* Epoch 10/10 5589/5589 - 40s 7ms/step - loss: 0.3639 - acc: 0.8583 - val_loss: 0.3662 - val_acc: 0.8585\n",
    "* 6987/6987 - 20s 3ms/step\n",
    "* loss= 3.3677486562448937\n",
    "* accuracy= 0.7690200838678228\n",
    "\n",
    "#### batch_size=128（4）\n",
    "* Epoch 1/10 5589/5589 - 37s 7ms/step - loss: 0.4471 - acc: 0.8469 - val_loss: 0.4210 - val_acc: 0.8571\n",
    "* Epoch 10/10 5589/5589 - 35s 6ms/step - loss: 0.3713 - acc: 0.8571 - val_loss: 0.3759 - val_acc: 0.8579\n",
    "* 6987/6987 - 20s 3ms/step\n",
    "* loss= 2.302585364104648\n",
    "* accuracy= 0.8571428656578064\n",
    "* plotが今までで一番綺麗\n",
    "\n",
    "#### img = img.resize((50, 50)) （5）\n",
    "* Epoch 1/10 5589/5589 - 12s 2ms/step - loss: 0.4850 - acc: 0.8341 - val_loss: 0.4227 - val_acc: 0.8571\n",
    "* Epoch 10/10 5589/5589 - 11s 2ms/step - loss: 0.3878 - acc: 0.8575 - val_loss: 0.3785 - val_acc: 0.8588\n",
    "* 6987/6987 - 5s 719us/step\n",
    "* loss= 2.3025854514599597\n",
    "* accuracy= 0.8571428656578064\n",
    "* 4と結果が同じ\n",
    "\n",
    "#### img = img.resize((70, 70)) （6）\n",
    "* Epoch 1/10 5589/5589 - 20s 4ms/step - loss: 0.4686 - acc: 0.8399 - val_loss: 0.4193 - val_acc: 0.8571\n",
    "* Epoch 10/10 5589/5589 - 19s 3ms/step - loss: 0.3809 - acc: 0.8572 - val_loss: 0.3755 - val_acc: 0.8558\n",
    "* 6987/6987 - 11s 2ms/step\n",
    "* loss= 2.3025853630127067\n",
    "* accuracy= 0.8571428656578064\n",
    "* imgsize((100, 100))~((50, 50))間で結果は変らないのだろうか\n",
    "\n",
    "#### img = img.resize((50, 50)) , epoc=15\n",
    "* Epoch 1/15 5589/5589 - 11s 2ms/step - loss: 0.4723 - acc: 0.8492 - val_loss: 0.4207 - val_acc: 0.8571\n",
    "* Epoch 15/15 5589/5589 - 11s 2ms/step - loss: 0.3813 - acc: 0.8573 - val_loss: 0.3818 - val_acc: 0.8569\n",
    "* 6987/6987 - 5s 705us/step\n",
    "* loss= 2.3025853630127067\n",
    "* accuracy= 0.8571428656578064\n",
    "* 結果に変化無し"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
