{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# èª²é¡Œ5 ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†æ\n",
    "é…ç‚¹\n",
    "- Q1, 1P\n",
    "- Q2.1, 0.5P\n",
    "- Q2.2, 0.5P\n",
    "- Q2.3, 1P\n",
    "- Q3.1, 1P\n",
    "- Q3.2, 2P\n",
    "- Q3.3, 2P\n",
    "- Q4, 2P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "$n$-æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã«ãŠã‘ã‚‹ã€ä»»æ„ã®2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«ã€$ \\vec{x}=(x_1,x_2,...,x_n)$ã€$\\vec{y}=(y_1,y_2,...,y_n)$ã€ã®é–“ã®cosé¡ä¼¼åº¦ $cos( \\vec{x}, \\vec{y})$ ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "$cos( \\vec{x}, \\vec{y}) =  \\frac{\\vec{x}\\cdot \\vec{y}}{\\|x\\|_2\\|y\\|_2}=\\frac{\\Sigma^{n}_{i=1}{x_{i}y_{i}}}{\\sqrt{\\Sigma^{n}_{i=1}x_{i}^{2}}\\sqrt{\\Sigma^{n}_{i=1}y_{i}^{2}}}$\n",
    "\n",
    "å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ« $\\vec{x}$, $\\vec{y}$ ã‚’ãã‚Œãã‚Œ`NumPy` ã®é…åˆ—ã¨ã—ã¦å¼•æ•°ã§å—ã‘å–ã‚Šã€ãã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«é–“ã®cosé¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¦è¿”ã™é–¢æ•° `cos_sim` ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def cos_sim(vec1, vec2):\n",
    "    v1_sum = 0\n",
    "    v2_sum = 0\n",
    "    for i in range(2):\n",
    "        v1_sum += vec1[i]**2\n",
    "        v2_sum += vec2[i]**2\n",
    "    return np.dot(vec1, vec2) / ((v1_sum**0.5)*(v2_sum**0.5))# (vec1ã¨vec2ã®å†…ç©)/np.sqrt(vec1ã®è¦ç´ ã®äºŒä¹—å’Œ*vec2ã®è¦ç´ ã®äºŒä¹—å’Œ)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cos_sim()`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚`-1.0, 1.0, 0.0`ãŒãã‚Œãã‚Œã®cosé¡ä¼¼åº¦ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(np.array([1,0]), np.array([-1,0])))\n",
    "print(cos_sim(np.array([1,0]), np.array([1,0])))\n",
    "print(cos_sim(np.array([1,0]), np.array([0,-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\"course_list.csv\"ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å„è¡Œã«æˆæ¥­åã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯UTF8ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã§ã¯ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å„æˆæ¥­ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆã—ã€æˆæ¥­é–“ã®é¡ä¼¼åº¦ã‚’æ±‚ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚\n",
    "```Python\n",
    "## course_list.csvãƒ•ã‚¡ã‚¤ãƒ«\n",
    "...\n",
    "è¨ˆé‡çµŒæ¸ˆå­¦â… \n",
    "æ•°ç†çµ±è¨ˆ\n",
    "è¨ˆé‡çµŒæ¸ˆå­¦\n",
    "çµŒæ¸ˆå²â…¡\n",
    "ICTãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆâ… \n",
    "ç¾ä»£æ—¥æœ¬çµŒæ¸ˆå²\n",
    "çµŒæ¸ˆå­¦å²\n",
    "...\n",
    "```\n",
    "ã¾ãšå¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’importã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1\n",
    "\"course_list.csv\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1è¡Œãšã¤**é †ç•ªã«**èª­ã¿è¾¼ã¿ã€ãã®å„è¡Œã‚’è¦ç´ ã¨ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¦è¿”ã™`course_list`é–¢æ•°ã‚’å®Œæˆã•ã¦ãã ã•ã„ã€‚ä½œæˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã¯å¤‰æ•°`courses`ã§å—ã‘å–ã‚Šã¾ã™ã€‚ä»¥é™ã®å‡¦ç†ã§ã¯ã€ãƒªã‚¹ãƒˆ`courses`ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãã®è¦ç´ ï¼ˆæˆæ¥­åï¼‰ã®IDã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_list():\n",
    "    lst=[]\n",
    "    with open('course_list.csv', 'r',  encoding=\"utf-8\") as f:\n",
    "        dataReader = csv.reader(f)\n",
    "        for row in dataReader:\n",
    "            lst.append(row[0])# lstã«row[0]ã‚’è¿½åŠ \n",
    "    return lst\n",
    "courses = course_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`course_list`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆã®é•·ã•ï¼ˆæˆæ¥­ã®æ•°ï¼‰ã¯`4678`ã€\"Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°\n",
    "å…¥é–€\"æˆæ¥­ã®IDï¼ˆãƒªã‚¹ãƒˆ`courses`ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã¯`6`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4678\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(courses))\n",
    "print(course_list().index('Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2\n",
    "\"keyword_list.csv\"ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å„è¡Œã«1å˜èªãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯UTF8ï¼‰ã€‚\n",
    "```Python\n",
    "## keyword_list.csvãƒ•ã‚¡ã‚¤ãƒ«\n",
    "...\n",
    "è³‡æº\n",
    "åºƒåŸŸ\n",
    "ãƒ•ãƒ©ãƒ³ã‚¹èª\n",
    "èªå­¦\n",
    "æ•™è‚²æ³•\n",
    "ç’°å¢ƒå­¦\n",
    "ç›¸é–¢\n",
    "è§£æå­¦\n",
    "æ£®æ—\n",
    "...\n",
    "```\n",
    "\"keywor_list.csv\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1è¡Œãšã¤**é †ç•ªã«**èª­ã¿è¾¼ã¿ã€ãã®å„è¡Œã‚’è¦ç´ ã¨ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¦è¿”ã™`vocab_list`é–¢æ•°ã‚’å®Œæˆã•ã¦ãã ã•ã„ã€‚ä½œæˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã¯å¤‰æ•°`vocab`ã§å—ã‘å–ã‚Šã¾ã™ã€‚ä»¥é™ã®å‡¦ç†ã§ã¯ã€ãƒªã‚¹ãƒˆ`vocab`ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãã®è¦ç´ ï¼ˆå˜èªï¼‰ã®IDã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚ãƒªã‚¹ãƒˆ`vocab`ã¯ä»¥é™ã®å‡¦ç†ã«ãŠã‘ã‚‹èªå½™ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_list():\n",
    "    lst = []\n",
    "    with open('keyword_list.csv', 'r',  encoding=\"utf-8\") as f:\n",
    "        dataReader = csv.reader(f)\n",
    "        for row in dataReader:\n",
    "            lst.append(row[0])\n",
    "    return lst\n",
    "vocab = vocab_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vocab_list`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãƒªã‚¹ãƒˆã®é•·ã•ï¼ˆå˜èªã®æ•°ï¼‰ã¯`910`ã€å˜èª\"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°\"ã®IDï¼ˆãƒªã‚¹ãƒˆ`vocab`ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã¯`113`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "113\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab.index('ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3\n",
    "ãƒªã‚¹ãƒˆ`courses`ã¨`vocab`ã‚’å¼•æ•°ã§å—ã‘å–ã‚Šã€å˜èªã®IDï¼ˆãƒªã‚¹ãƒˆ`vocab`ã®ãã®å˜èªã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã‚’ã‚­ãƒ¼ã€ãã®å˜èªã®DFï¼ˆDocument Frequency)ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã—ã¦è¿”ã™`count_df`é–¢æ•°ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä½œæˆã•ã‚ŒãŸè¾æ›¸ã¯å¤‰æ•°`df`ã§å—ã‘å–ã‚Šã¾ã™ã€‚ã“ã®å ´åˆã€ã‚ã‚‹å˜èªã®DFã¯ãã®å˜èªã‚’æˆæ¥­åã«å«ã‚€æˆæ¥­æ•°ã«å¯¾å¿œã—ã¾ã™ã€‚**å˜èªãŒæˆæ¥­åã«è¤‡æ•°å›å«ã¾ã‚Œã‚‹å ´åˆã§ã‚‚1å›ã¨æ•°ãˆã¾ã™**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_df(courses, vocab): #Document Frequency\n",
    "    dic={}\n",
    "    for i in range(len(vocab)):\n",
    "        for course in courses:\n",
    "            if vocab[i] in course: #courseãŒvocab[i]ã‚’å«ã‚€ã¨ã„ã†æ¡ä»¶:\n",
    "                if not i in dic:\n",
    "                    dic[i] = 0\n",
    "                dic[i] += 1 #dic[i]ã‚’1ã¤å¢—ã‚„ã™\n",
    "                #dicã«iã®ã‚­ãƒ¼ãŒã¾ã ãªã„å ´åˆã«æ³¨æ„\n",
    "    return dic\n",
    "df = count_df(courses, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count_df`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è¾æ›¸ã®é•·ã•ã¯`910`ã€å˜èª\"ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°\"ï¼ˆIDã¯`113`ï¼‰ã®DFã¯`23`ã€å˜èª\"è‹±èª\"ï¼ˆIDã¯`15`ï¼‰ã®DFã¯`145`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n",
      "113 23\n",
      "15 145\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(vocab.index('ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'), df[vocab.index('ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°')])\n",
    "print(vocab.index('è‹±èª'), df[vocab.index('è‹±èª')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "### Q3.1\n",
    "ãƒªã‚¹ãƒˆ`vocab`ã®å„å˜èªã‚’æ¬¡å…ƒã¨ã™ã‚‹æˆæ¥­ãƒ™ã‚¯ãƒˆãƒ«ã‚’è€ƒãˆã¾ã™ã€‚æˆæ¥­ãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ã¯ãƒªã‚¹ãƒˆ`vocab`ã®é•·ã•ã¨ç­‰ã—ãã€ãƒªã‚¹ãƒˆ`vocab`ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹`i`ã®å˜èª`vocab[i]`ãŒæˆæ¥­åã«å«ã¾ã‚Œã‚‹æ™‚ã€æˆæ¥­ãƒ™ã‚¯ãƒˆãƒ«ã®`i`ç•ªç›®ã®è¦ç´ ã¯`1`ã€å«ã¾ã‚Œãªã‘ã‚Œã°`0`ã¨ã—ã¾ã™ã€‚\n",
    "\n",
    "ä»¥ä¸‹ã§ã¯ã€ãƒªã‚¹ãƒˆ`courses`ã¨`vocab`ã‚’å¼•æ•°ã§å—ã‘å–ã‚Šã€ãƒªã‚¹ãƒˆ`courses`ã®å„æˆæ¥­ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¡Œã€ãƒªã‚¹ãƒˆ`vocab`ã®å„å˜èªã‚’åˆ—ã¨ã—ãŸ`NumPy`ã®è¡Œåˆ—ã‚’ä½œæˆã—ã¦è¿”ã™`lec_word_matrix`é–¢æ•°ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã¯ã€æˆæ¥­ï¼ˆè¡Œï¼‰ã®æˆæ¥­åã«å˜èªï¼ˆåˆ—ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ã€ãã®è¦ç´ ãŒ1ã§ã‚ã‚‹ã‚ˆã†ãªè¡Œåˆ—ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document-term matrix\n",
    "def lec_word_matrix(courses, vocab):\n",
    "    mat = np.zeros((len(courses), len(vocab))) #æˆæ¥­æ•°xå˜èªæ•°ã®0è¦ç´ ã®è¡Œåˆ—ã‚’åˆæœŸåŒ–\n",
    "    for i in range(len(courses)):\n",
    "        for j in range(len(vocab)):\n",
    "            if vocab[j] in courses[i]:#courses[i]ãŒvocab[i]ã‚’å«ã‚€ã¨ã„ã†æ¡ä»¶:\n",
    "                mat[i, j] = 1# mat[i, j]ã«1ã‚’ä»£å…¥\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lec_word_matrix`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®è¦ç´ ã®å€¤ã®å’Œã¯`17406`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17406.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lec_word_matrix(courses, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "Q3.1ã§ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®å„è¦ç´ ã‚’ã€ãã®æˆæ¥­ã®æˆæ¥­åã«å˜èªãŒå«ã¾ã‚Œã‚‹ã‹å¦ã‹ã®1or0ã§ã¯ãªãã€ãã®æˆæ¥­ã®æˆæ¥­åã«å˜èªãŒä½•å›å«ã¾ã‚Œã‚‹ã‹ï¼ˆTF: Term Frequency)ã§è¡¨ã—ãŸè¡Œåˆ—ã‚’ä½œæˆã—ã¦è¿”ã™`lec_word_tf_matrix`é–¢æ•°ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document-term matrix\n",
    "def lec_word_tf_matrix(courses, vocab):\n",
    "    mat = np.zeros((len(courses), len(vocab))) # æˆæ¥­æ•°xå˜èªæ•°ã®0è¦ç´ ã®è¡Œåˆ—ã‚’åˆæœŸåŒ–\n",
    "    for i in range(len(courses)):\n",
    "        for j in range(len(vocab)):\n",
    "            if vocab[j] in courses[i]:# courses[i]ãŒvocab[i]ã‚’å«ã‚€ã¨ã„ã†æ¡ä»¶:\n",
    "                 mat[i, j] = courses[i].count(vocab[j])# courses[i]ã«å«ã¾ã‚Œã‚‹vocab[j]ã®æ•°ï¼ˆãƒ’ãƒ³ãƒˆ count())ã‚’mat[i, j]ã«ä»£å…¥\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lec_word_tf_matrix`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®è¦ç´ ã®å€¤ã®å’Œã¯`17732`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17732.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lec_word_tf_matrix(courses, vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆæ¥­ã€Œç·åˆç¤¾ä¼šç§‘å­¦é«˜åº¦æ•™é¤Šï¼ˆè¨ˆé‡ç¤¾ä¼šç§‘å­¦ç ”ç©¶ï¼‰ã€ã«ã¯ã€Œç§‘å­¦ã€ãŒ2å›å«ã¾ã‚Œã‚‹ã®ã§å¯¾å¿œã™ã‚‹è¡Œåˆ—ã®è¦ç´ ã®å€¤ã¯2ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lec_word_tf_matrix(courses, vocab)[courses.index('ç·åˆç¤¾ä¼šç§‘å­¦é«˜åº¦æ•™é¤Šï¼ˆè¨ˆé‡ç¤¾ä¼šç§‘å­¦ç ”ç©¶ï¼‰'), vocab.index('ç§‘å­¦')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3\n",
    "Q3.2ã§ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®å„è¦ç´ ï¼ˆæˆæ¥­`i`ã®å˜èª`j`ã®$TF_{ij}$ï¼‰ã«ãã®å˜èªã®IDFå€¤ã‚’æ›ã‘ãŸTFIDFå€¤ã‚’è¦ç´ ã¨ã™ã‚‹è¡Œåˆ—ã‚’ä½œæˆã—ã¦è¿”ã™`lec_word_tfidf_matrix`é–¢æ•°ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸè¡Œåˆ—ã¯å¤‰æ•°`tfidf_matrix`ã§å—ã‘å–ã‚Šã¾ã™ã€‚\n",
    "\n",
    "ã“ã“ã§ã€æˆæ¥­`i`ã€å˜èª`j`ã®TFIDFå€¤ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¾ã™ã€‚\n",
    "```Python\n",
    "TFIDF=TF_ij*log(ã™ã¹ã¦ã®æˆæ¥­æ•°/å˜èªjã®DF)=TF_ij*log(len(courses)/df[j])\n",
    "```\n",
    "`log`ã®è¨ˆç®—ã«ã¯`np.log()`ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã„ã§ã™ã€‚\n",
    "\n",
    "`lec_word_tfidf_matrix`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®è¦ç´ ã®å€¤ã®å’Œã®æ•´æ•°éƒ¨åˆ†ã¯`76994`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lec_word_tfidf_matrix(courses, vocab, df):\n",
    "    ### å¼•æ•°:\n",
    "    # courses: æˆæ¥­ãƒªã‚¹ãƒˆ\n",
    "    # vocab: å˜èªãƒªã‚¹ãƒˆ\n",
    "    # df: DFè¾æ›¸\n",
    "    df = count_df(courses, vocab)\n",
    "    TF_ij = lec_word_tf_matrix(courses, vocab) #Q3.2ã§ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®å„è¦ç´ ï¼ˆæˆæ¥­iã®å˜èªjã® ğ‘‡ğ¹ğ‘–ğ‘—)\n",
    "    tfidf_matrix = np.zeros((len(courses), len(vocab))) \n",
    "    for i in range(len(courses)):\n",
    "        for j in range(len(vocab)):\n",
    "            # ãã®å˜èªã®IDFå€¤ = np.log(len(courses)/df[j])\n",
    "            tfidf_matrix[i, j] = TF_ij[i, j]*np.log(len(courses)/df[j])\n",
    "    ###  Q3.2ã®mat[i,j]ã‚’\"æˆæ¥­åiã®å˜èªjã®TFIDFå€¤\"ã¨ã—ãŸè¡Œåˆ—ã‚’ä½œæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ ###\n",
    "    return tfidf_matrix### ä¸Šè¨˜ã§ä½œæˆã—ãŸè¡Œåˆ—ã‚’è¿”ã™ ###\n",
    "tfidf_matrix = lec_word_tfidf_matrix(courses, vocab, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lec_word_tfidf_matrix`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã®è¦ç´ ã®å€¤ã®å’Œã®æ•´æ•°éƒ¨åˆ†ã¯`76994`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76994.09284193128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lec_word_tfidf_matrix(courses, vocab, df))\n",
    "#np.sum(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆæ¥­ã€Œç·åˆç¤¾ä¼šç§‘å­¦é«˜åº¦æ•™é¤Šï¼ˆè¨ˆé‡ç¤¾ä¼šç§‘å­¦ç ”ç©¶ï¼‰ã€ã«ã¯ã€Œç§‘å­¦ã€ãŒ`2`å›å«ã¾ã‚Œã€ã€Œç§‘å­¦ã€ã®DFå€¤ã¯`412`ãªã®ã§å¯¾å¿œã™ã‚‹è¡Œåˆ—ã®è¦ç´ ã®å€¤ã¯$2*log(4678/412)\\simeq4.85$ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n",
      "4.859205195589196\n"
     ]
    }
   ],
   "source": [
    "print(df[vocab.index('ç§‘å­¦')])\n",
    "print(tfidf_matrix[courses.index('ç·åˆç¤¾ä¼šç§‘å­¦é«˜åº¦æ•™é¤Šï¼ˆè¨ˆé‡ç¤¾ä¼šç§‘å­¦ç ”ç©¶ï¼‰'), vocab.index('ç§‘å­¦')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "Q3.3ã§ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—ã‚’å…ƒã«ã€å…¥åŠ›ã®æˆæ¥­ã«å¯¾ã—ã¦cosé¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ä»–ã®ã™ã¹ã¦ã®æˆæ¥­ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€é¡ä¼¼ã™ã‚‹æˆæ¥­åã‚’ã‚­ãƒ¼ã€ãã®é¡ä¼¼åº¦ã‚’å€¤ã¨ã—ãŸè¾æ›¸ã‚’è¿”ã™ä»¥ä¸‹ã®`find_similar_course`é–¢æ•°ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚ãã®éš›ã€å…¥åŠ›ã®æˆæ¥­ãŠã‚ˆã³é¡ä¼¼åº¦ãŒ0ã®æˆæ¥­ã¯è¾æ›¸ã«å«ã‚ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚cosé¡ä¼¼åº¦ã®è¨ˆç®—ã«ã¯Q1ã§ä½œæˆã—ãŸé–¢æ•°ã‚’ä½¿ã£ã¦ã‚‚ã‚ˆã„ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_course(target, tfidf_matrix, courses):\n",
    "    ### å¼•æ•°ï¼š\n",
    "    # target:  å…¥åŠ›æˆæ¥­ã®ID\n",
    "    # tfidf_matrix: Q3.3ã§ä½œæˆã—ãŸæˆæ¥­-å˜èªè¡Œåˆ—\n",
    "    # courses: æˆæ¥­ãƒªã‚¹ãƒˆ    \n",
    "    ### å…¥åŠ›æˆæ¥­ã®ãƒ™ã‚¯ãƒˆãƒ«tfidf_matrix[target]ã¨å„æˆæ¥­iã®ãƒ™ã‚¯ãƒˆãƒ«tfidf_matrix[i]ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã‚³ãƒ¼ãƒ‰ ###\n",
    "    dic_cos = {}\n",
    "    for i in range(len(courses)):\n",
    "        if cos_sim(np.array(tfidf_matrix[target]), np.array(tfidf_matrix[i])) != 0:\n",
    "            dic_cos[courses[i]] = cos_sim(np.array(tfidf_matrix[target]), np.array(tfidf_matrix[i]))\n",
    "    return dic_cos ### é¡ä¼¼ã™ã‚‹æˆæ¥­åã‚’ã‚­ãƒ¼ã€ãã®é¡ä¼¼åº¦ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸ã‚’è¿”ã™ ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_similar_course`é–¢æ•°ãŒå®Œæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å‹•ä½œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚å…¥åŠ›ã®æˆæ¥­`å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨å…¬å…±æ”¿ç­–`ã«é¡ä¼¼ã—ãŸä¸Šä½ã®æˆæ¥­ã¯ã€`å…¬å…±æ”¿ç­–ã€é‡‘èå¸‚å ´ã¨å…¬å…±æ”¿ç­–ã€æ–‡åŒ–äººé¡å­¦ç‰¹æ®Šæ¼”ç¿’ï¼ˆå…¬å…±æ”¿ç­–è«–ï¼‰ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–ã€æ²³å·æµåŸŸã®ç’°å¢ƒã¨ãã®å†ç”Ÿã€...`ã¨ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨å…¬å…±æ”¿ç­–</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>å…¬å…±æ”¿ç­–</td>\n",
       "      <td>0.649841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>é‡‘èå¸‚å ´ã¨å…¬å…±æ”¿ç­–</td>\n",
       "      <td>0.483719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>æ–‡åŒ–äººé¡å­¦ç‰¹æ®Šæ¼”ç¿’ï¼ˆå…¬å…±æ”¿ç­–è«–ï¼‰</td>\n",
       "      <td>0.475690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–</td>\n",
       "      <td>0.442935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>æ²³å·æµåŸŸã®ç’°å¢ƒã¨ãã®å†ç”Ÿ</td>\n",
       "      <td>0.413535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»è³‡æºæ”¿ç­–è«–</td>\n",
       "      <td>0.366721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ç™ºç”Ÿãƒ»å†ç”Ÿç”Ÿç‰©å­¦</td>\n",
       "      <td>0.303553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>å…¬å…±çµŒå–¶å­¦</td>\n",
       "      <td>0.277481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰æ›å·¥å­¦</td>\n",
       "      <td>0.267711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  similarity\n",
       "3     å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨å…¬å…±æ”¿ç­–    1.000000\n",
       "27              å…¬å…±æ”¿ç­–    0.649841\n",
       "4          é‡‘èå¸‚å ´ã¨å…¬å…±æ”¿ç­–    0.483719\n",
       "31  æ–‡åŒ–äººé¡å­¦ç‰¹æ®Šæ¼”ç¿’ï¼ˆå…¬å…±æ”¿ç­–è«–ï¼‰    0.475690\n",
       "1            ã‚¨ãƒãƒ«ã‚®ãƒ¼æ”¿ç­–    0.442935\n",
       "63      æ²³å·æµåŸŸã®ç’°å¢ƒã¨ãã®å†ç”Ÿ    0.413535\n",
       "46       ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»è³‡æºæ”¿ç­–è«–    0.366721\n",
       "13          ç™ºç”Ÿãƒ»å†ç”Ÿç”Ÿç‰©å­¦    0.303553\n",
       "62             å…¬å…±çµŒå–¶å­¦    0.277481\n",
       "57         ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰æ›å·¥å­¦    0.267711"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "title=\"å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã¨å…¬å…±æ”¿ç­–\" # å…¥åŠ›ã®æˆæ¥­å\n",
    "results=find_similar_course(courses.index(title), tfidf_matrix, courses) # é¡ä¼¼æˆæ¥­ã®è¾æ›¸ã‚’å—ã‘å–ã‚‹\n",
    "df=pd.DataFrame(list(results.items()), columns=['title', \"similarity\"]) # é¡ä¼¼åº¦ãŒä¸Šä½ã®æˆæ¥­ã‚’è¡¨ç¤º\n",
    "df.sort_values(by='similarity', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
