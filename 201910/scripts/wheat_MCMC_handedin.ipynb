{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方針\n",
    " ※ 使用データ...頂いた小麦のデータ\n",
    "1. 適切な塩基の組み合わせを選ぶ（特徴量選択）\n",
    "2. １で選んだ転写因子の組み合わせを選んだときにもっともエネルギーが低くなるような関数を設定する\n",
    "3. 表現型(収穫量)の要素を一つずつ変化させる。この前後でエネルギーがどのくらい変わったのか確認する（比）。\n",
    "4. 乱数(0 ≦ R ≦ 1の一様乱数)より高かったら採択、低かったら棄却\n",
    "5. ３に戻る\n",
    "6. ４に100回たどり着くたびにlistに記録\n",
    "\n",
    "\n",
    "### 仮定\n",
    "- 小麦データの収量行列は１行４列。\n",
    "- 候補として最大値、最長値、平均値を考えたが、今回は0列目を使うことにする（よう言われました）\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### 1. 特徴量選択\n",
    "(考え)変数間の相互作用を考えたほうが良いのだろう、反復特徴量選択は時間がかかる→モデルベース特徴量選択 <br/>\n",
    "(結論)1279塩基から640塩基が残った"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SNPサンプル数, 塩基数)= (599, 1279)\n"
     ]
    }
   ],
   "source": [
    "# 説明変数\n",
    "import pandas as pd\n",
    "data_SNP = pd.read_table('CIMMYTwheat_markers.txt', header=None,  sep =  ' ')\n",
    "print('(SNPサンプル数, 塩基数)=', data_SNP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNPサンプル数： 599\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(599, 4)\n",
      "0    1.671629\n",
      "1   -1.727470\n",
      "2   -1.890285\n",
      "3    0.050916\n",
      "Name: 0, dtype: float64\n",
      "1.671629\n",
      "599\n",
      "<class 'list'>\n",
      "0.7854395000000001\n"
     ]
    }
   ],
   "source": [
    "# 目的変数\n",
    "data_yields = pd.read_table('CIMMYTwheat_yields.txt', header=None,  sep =  ' ')\n",
    "print('SNPサンプル数：', len(data_yields))\n",
    "print(type(data_yields))\n",
    "print(data_yields.shape)\n",
    "print(data_yields.iloc[0]) #0行目\n",
    "print(data_yields.iloc[0, 0]) #[0, 0]\n",
    "\n",
    "'''\n",
    "data_amount_list = []\n",
    "for i in range(len(data_yields)):\n",
    "    canditate = data_yields.iloc[i, 0]\n",
    "    for j in range(1, 4):\n",
    "        if data_yields.iloc[i, j] >= canditate:\n",
    "            canditate = data_yields.iloc[i, j]\n",
    "    data_amount_list.append(canditate)\n",
    "'''\n",
    "\n",
    "data_amount_list = []\n",
    "for i in range(len(data_yields)):\n",
    "    data_amount_list.append(data_yields.iloc[i, 0])\n",
    "\n",
    "#print(data_amount)\n",
    "print(len(data_amount_list))\n",
    "print(type(data_amount_list))\n",
    "print(data_amount_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_amount = pd.Series(data_amount_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_SNP, data_amount, test_size=0.3) #x, y ,test0.3, train0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(419,)\n",
      "1\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.ndim)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.ndim)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: -0.00\n",
      "Number of features used: 0\n"
     ]
    }
   ],
   "source": [
    "# Lasso回帰\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(x_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(x_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (419, 1279)\n",
      "x_train_l1_shape: (419, 640)\n",
      "[ True False  True ...  True  True False]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# モデルベース特徴量選択（embedded method、組み込み法）\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# estimator として RandomForestRegressor を使用。重要度が median 以上のものを選択\n",
    "select = SelectFromModel(RandomForestRegressor(n_estimators = 100, random_state = 42), threshold = 'median')\n",
    "select.fit(x_train, y_train)\n",
    "\n",
    "#yはselect.fitしなくていい\n",
    "x_train_selected = select.transform(x_train)\n",
    "x_test_selected = select.transform(x_test)\n",
    "\n",
    "print('x_train.shape: {}'.format(x_train.shape))\n",
    "print('x_train_l1_shape: {}'.format(x_train_selected.shape))\n",
    "\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "print(type(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n",
      "<class 'numpy.ndarray'>\n",
      "1279\n"
     ]
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "print(mask)\n",
    "print(type(mask))\n",
    "print(len(mask)) #もとの特徴量の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "train_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(utils.multiclass.type_of_target(train_scores_encoded))\n",
    "\n",
    "test_scores_encoded = lab_enc.fit_transform(y_test)\n",
    "print(utils.multiclass.type_of_target(test_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コード確認しました。\n",
    "まずLogisticRegressionの学習のほう\n",
    "train_scores_encoded, test_scores_encodedというのは、それぞれy_train, y_testの中の順位をとったものになっていますね (例えば、y_train = [42.0, 1.0, 3.141, 2.718, 0.0]の場合、train_scores_encoded = [4, 1, 3, 2, 0])。予測モデルは与えられた入力だけから出力を予測するので、全体のデータセットを知らないのに順位を予測しなさいといってもできません。つまりスコアも低くなります。\n",
    "予測モデルを作るのであれば、LinearRegression等にしてx_trainからy_trainを直接予測するのがよいと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.00\n",
      "Test set score: -2.23\n"
     ]
    }
   ],
   "source": [
    "#線形回帰（最小二乗法）\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(x_test_selected, y_test)))\n",
    "# 過剰適合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.98\n",
      "Test set score: -0.71\n"
     ]
    }
   ],
   "source": [
    "# リッジ回帰(デフォルトで、alpha=1.0)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# まだ過剰適合\n",
    "\n",
    "# 係数とは w のこと\n",
    "# Ridgeモデルでは、モデルの簡潔さ（絶対値が0に近い係数の数）と訓練セットに対する性能がトレードオフ\n",
    "# alphaを増やすと、係数はより0に近くなり、訓練セットに対する性能は低下するが、汎化にはそのほうが良い可能性もある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.88\n",
      "Test set score: 0.01\n"
     ]
    }
   ],
   "source": [
    "# リッジ回帰(alpha=10)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 10).fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# alpha=10にしたにもかかわらずテストスコアが低すぎる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.83\n",
      "Test set score: 0.10\n"
     ]
    }
   ],
   "source": [
    "# リッジ回帰\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 20).fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# まだ過剰適合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(学習に関してわかったこと)<br/>\n",
    "- （特徴量選択＋）線形回帰では表せない（教師あり学習、線形回帰）\n",
    "- lasso回帰でしてもスコアでない\n",
    "- 今回は0列目を使ったが、別の値を使ったら精度が上がるかもしれない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_selected.shape : (419, 640)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#モデルベース特徴量選択を用いた結果\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "score = LogisticRegression().fit(x_train_selected, train_scores_encoded).score(x_test_selected, test_scores_encoded)\n",
    "print(f\"x_train_selected.shape : {x_train_selected.shape}\")\n",
    "#print(f'Score with only selected features : {score:.3f}')\n",
    "\n",
    "\n",
    "#score = LogisticRegression().fit(x_train_l1, y_train).score(x_test_selected, y_test)\n",
    "#print(\"Test score: {:.3f}\".format(score))  # 0と出る\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  確率場\n",
    "\n",
    "- 確率場$Z$がギブス的である ⇔ そのときに確率密度関数が👇となっている\n",
    "$$\n",
    "f(z) =  \\frac{e^{-E(z)}}{Z}\n",
    "$$\n",
    "<br/>\n",
    "- エネルギー関数$E$をもつギブス分布（or ボルツマン分布）= 👆に対応して定まる分布\n",
    "- $Z$は定数\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "### 2. エネルギー関数の設定\n",
    "- $E()$の設定→元祖maskが一番小さくなるように、相互情報量ではmask同士が一番大きくなる\n",
    "- 確率をどう書くか→$f(z)$の設定、定数は無視\n",
    "- エネルギーの大きさ比較→比を計算\n",
    "- 乱数発生→uniform...\n",
    "- 採択、棄却→更新するか否かの決断、エネルギーが一つ前のより小さかったら採択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = [] #Eは配列、どんどん入れていく(一つ後ろで計算の際使用される)\n",
    "def Energy(mask_trial):\n",
    "    return 1-normalized_mutual_info_score(mask_trial, mask) #エネルギーの定義≡1-標準化相互情報量 とした\n",
    "#np.append(E, Energy(mask)) #第一要素を追加\n",
    "E.append(Energy(mask))\n",
    "#print(Energy(mask))\n",
    "#print(mask)\n",
    "print(type(E))\n",
    "print(E[0])\n",
    "\n",
    "\n",
    "#mask_trial ...new_yによって選ばれた塩基mask(x)、forループを回すたび値が変わる、maskと比較するためにあるだけなので保存する必要なし\n",
    "\n",
    "save_y = [] #ほしいベクトルを貯める配列\n",
    "new_y = data_amount #以降要素を一つずつ変えていく #data_amountはSeries\n",
    "\n",
    "import math\n",
    "\n",
    "for i in range(1, 100):   \n",
    "    new_y[i] = 1 - new_y[i] #要素一つだけ変えた\n",
    "    \n",
    "    select = SelectFromModel(RandomForestRegressor(n_estimators = 100, random_state = 42), threshold = 'median', max_features=640)\n",
    "    select.fit(data_SNP, new_y)\n",
    "    data_SNP_l1 = select.transform(data_SNP)\n",
    "    mask_trial = select.get_support()\n",
    "\n",
    "    #np.append(E, Energy(mask_trial))  #mask_trialは一つのndarrayの中で順番に要素を更新していく\n",
    "    E.append(Energy(mask_trial))\n",
    "    r = math.exp(-E[i])/math.exp(-E[i-1])\n",
    "    R = np.random.uniform(0.0, 1.0)\n",
    "    if R >= r : #f(z)が一個前のものよりも小さかったら⇔E[i]が一個前のものよりも大きかったら\n",
    "        new_y[i] =1 - new_y[i] #元に戻す   \n",
    "    if i%100 == 0:\n",
    "        save_y.append(new_y)\n",
    "    else:\n",
    "            continue\n",
    "    if len(save_y) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
