{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ–¹é‡\n",
    " â€» ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿...é ‚ã„ãŸå°éº¦ã®ãƒ‡ãƒ¼ã‚¿\n",
    "1. é©åˆ‡ãªå¡©åŸºã®çµ„ã¿åˆã‚ã›ã‚’é¸ã¶ï¼ˆç‰¹å¾´é‡é¸æŠï¼‰\n",
    "2. ï¼‘ã§é¸ã‚“ã è»¢å†™å› å­ã®çµ„ã¿åˆã‚ã›ã‚’é¸ã‚“ã ã¨ãã«ã‚‚ã£ã¨ã‚‚ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä½ããªã‚‹ã‚ˆã†ãªé–¢æ•°ã‚’è¨­å®šã™ã‚‹\n",
    "3. è¡¨ç¾å‹(åç©«é‡)ã®è¦ç´ ã‚’ä¸€ã¤ãšã¤å¤‰åŒ–ã•ã›ã‚‹ã€‚ã“ã®å‰å¾Œã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒã©ã®ãã‚‰ã„å¤‰ã‚ã£ãŸã®ã‹ç¢ºèªã™ã‚‹ï¼ˆæ¯”ï¼‰ã€‚\n",
    "4. ä¹±æ•°(0 â‰¦ R â‰¦ 1ã®ä¸€æ§˜ä¹±æ•°)ã‚ˆã‚Šé«˜ã‹ã£ãŸã‚‰æ¡æŠã€ä½ã‹ã£ãŸã‚‰æ£„å´\n",
    "5. ï¼“ã«æˆ»ã‚‹\n",
    "6. ï¼”ã«100å›ãŸã©ã‚Šç€ããŸã³ã«listã«è¨˜éŒ²\n",
    "\n",
    "\n",
    "### ä»®å®š\n",
    "- å°éº¦ãƒ‡ãƒ¼ã‚¿ã®åé‡è¡Œåˆ—ã¯ï¼‘è¡Œï¼”åˆ—ã€‚\n",
    "- å€™è£œã¨ã—ã¦æœ€å¤§å€¤ã€æœ€é•·å€¤ã€å¹³å‡å€¤ã‚’è€ƒãˆãŸãŒã€ä»Šå›ã¯0åˆ—ç›®ã‚’ä½¿ã†ã“ã¨ã«ã™ã‚‹ï¼ˆã‚ˆã†è¨€ã‚ã‚Œã¾ã—ãŸï¼‰\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### 1. ç‰¹å¾´é‡é¸æŠ\n",
    "(è€ƒãˆ)å¤‰æ•°é–“ã®ç›¸äº’ä½œç”¨ã‚’è€ƒãˆãŸã»ã†ãŒè‰¯ã„ã®ã ã‚ã†ã€åå¾©ç‰¹å¾´é‡é¸æŠã¯æ™‚é–“ãŒã‹ã‹ã‚‹â†’ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠ <br/>\n",
    "(çµè«–)1279å¡©åŸºã‹ã‚‰640å¡©åŸºãŒæ®‹ã£ãŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SNPã‚µãƒ³ãƒ—ãƒ«æ•°, å¡©åŸºæ•°)= (599, 1279)\n"
     ]
    }
   ],
   "source": [
    "# èª¬æ˜å¤‰æ•°\n",
    "import pandas as pd\n",
    "data_SNP = pd.read_table('CIMMYTwheat_markers.txt', header=None,  sep =  ' ')\n",
    "print('(SNPã‚µãƒ³ãƒ—ãƒ«æ•°, å¡©åŸºæ•°)=', data_SNP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNPã‚µãƒ³ãƒ—ãƒ«æ•°ï¼š 599\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(599, 4)\n",
      "0    1.671629\n",
      "1   -1.727470\n",
      "2   -1.890285\n",
      "3    0.050916\n",
      "Name: 0, dtype: float64\n",
      "1.671629\n",
      "599\n",
      "<class 'list'>\n",
      "0.7854395000000001\n"
     ]
    }
   ],
   "source": [
    "# ç›®çš„å¤‰æ•°\n",
    "data_yields = pd.read_table('CIMMYTwheat_yields.txt', header=None,  sep =  ' ')\n",
    "print('SNPã‚µãƒ³ãƒ—ãƒ«æ•°ï¼š', len(data_yields))\n",
    "print(type(data_yields))\n",
    "print(data_yields.shape)\n",
    "print(data_yields.iloc[0]) #0è¡Œç›®\n",
    "print(data_yields.iloc[0, 0]) #[0, 0]\n",
    "\n",
    "'''\n",
    "data_amount_list = []\n",
    "for i in range(len(data_yields)):\n",
    "    canditate = data_yields.iloc[i, 0]\n",
    "    for j in range(1, 4):\n",
    "        if data_yields.iloc[i, j] >= canditate:\n",
    "            canditate = data_yields.iloc[i, j]\n",
    "    data_amount_list.append(canditate)\n",
    "'''\n",
    "\n",
    "data_amount_list = []\n",
    "for i in range(len(data_yields)):\n",
    "    data_amount_list.append(data_yields.iloc[i, 0])\n",
    "\n",
    "#print(data_amount)\n",
    "print(len(data_amount_list))\n",
    "print(type(data_amount_list))\n",
    "print(data_amount_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_amount = pd.Series(data_amount_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_SNP, data_amount, test_size=0.3) #x, y ,test0.3, train0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(419,)\n",
      "1\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.ndim)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_test.ndim)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: -0.00\n",
      "Number of features used: 0\n"
     ]
    }
   ],
   "source": [
    "# Lassoå›å¸°\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(x_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(x_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(x_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (419, 1279)\n",
      "x_train_l1_shape: (419, 640)\n",
      "[ True False  True ...  True  True False]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠï¼ˆembedded methodã€çµ„ã¿è¾¼ã¿æ³•ï¼‰\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# estimator ã¨ã—ã¦ RandomForestRegressor ã‚’ä½¿ç”¨ã€‚é‡è¦åº¦ãŒ median ä»¥ä¸Šã®ã‚‚ã®ã‚’é¸æŠ\n",
    "select = SelectFromModel(RandomForestRegressor(n_estimators = 100, random_state = 42), threshold = 'median')\n",
    "select.fit(x_train, y_train)\n",
    "\n",
    "#yã¯select.fitã—ãªãã¦ã„ã„\n",
    "x_train_selected = select.transform(x_train)\n",
    "x_test_selected = select.transform(x_test)\n",
    "\n",
    "print('x_train.shape: {}'.format(x_train.shape))\n",
    "print('x_train_l1_shape: {}'.format(x_train_selected.shape))\n",
    "\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "print(type(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n",
      "<class 'numpy.ndarray'>\n",
      "1279\n"
     ]
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "print(mask)\n",
    "print(type(mask))\n",
    "print(len(mask)) #ã‚‚ã¨ã®ç‰¹å¾´é‡ã®æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "train_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "print(utils.multiclass.type_of_target(train_scores_encoded))\n",
    "\n",
    "test_scores_encoded = lab_enc.fit_transform(y_test)\n",
    "print(utils.multiclass.type_of_target(test_scores_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ã‚³ãƒ¼ãƒ‰ç¢ºèªã—ã¾ã—ãŸã€‚\n",
    "ã¾ãšLogisticRegressionã®å­¦ç¿’ã®ã»ã†\n",
    "train_scores_encoded, test_scores_encodedã¨ã„ã†ã®ã¯ã€ãã‚Œãã‚Œy_train, y_testã®ä¸­ã®é †ä½ã‚’ã¨ã£ãŸã‚‚ã®ã«ãªã£ã¦ã„ã¾ã™ã­ (ä¾‹ãˆã°ã€y_train = [42.0, 1.0, 3.141, 2.718, 0.0]ã®å ´åˆã€train_scores_encoded = [4, 1, 3, 2, 0])ã€‚äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¯ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›ã ã‘ã‹ã‚‰å‡ºåŠ›ã‚’äºˆæ¸¬ã™ã‚‹ã®ã§ã€å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’çŸ¥ã‚‰ãªã„ã®ã«é †ä½ã‚’äºˆæ¸¬ã—ãªã•ã„ã¨ã„ã£ã¦ã‚‚ã§ãã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã‚¹ã‚³ã‚¢ã‚‚ä½ããªã‚Šã¾ã™ã€‚\n",
    "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã®ã§ã‚ã‚Œã°ã€LinearRegressionç­‰ã«ã—ã¦x_trainã‹ã‚‰y_trainã‚’ç›´æ¥äºˆæ¸¬ã™ã‚‹ã®ãŒã‚ˆã„ã¨æ€ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.00\n",
      "Test set score: -2.23\n"
     ]
    }
   ],
   "source": [
    "#ç·šå½¢å›å¸°ï¼ˆæœ€å°äºŒä¹—æ³•ï¼‰\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(x_test_selected, y_test)))\n",
    "# éå‰°é©åˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.98\n",
      "Test set score: -0.71\n"
     ]
    }
   ],
   "source": [
    "# ãƒªãƒƒã‚¸å›å¸°(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€alpha=1.0)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# ã¾ã éå‰°é©åˆ\n",
    "\n",
    "# ä¿‚æ•°ã¨ã¯ w ã®ã“ã¨\n",
    "# Ridgeãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ç°¡æ½”ã•ï¼ˆçµ¶å¯¾å€¤ãŒ0ã«è¿‘ã„ä¿‚æ•°ã®æ•°ï¼‰ã¨è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹æ€§èƒ½ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•\n",
    "# alphaã‚’å¢—ã‚„ã™ã¨ã€ä¿‚æ•°ã¯ã‚ˆã‚Š0ã«è¿‘ããªã‚Šã€è¨“ç·´ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹æ€§èƒ½ã¯ä½ä¸‹ã™ã‚‹ãŒã€æ±åŒ–ã«ã¯ãã®ã»ã†ãŒè‰¯ã„å¯èƒ½æ€§ã‚‚ã‚ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.88\n",
      "Test set score: 0.01\n"
     ]
    }
   ],
   "source": [
    "# ãƒªãƒƒã‚¸å›å¸°(alpha=10)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 10).fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# alpha=10ã«ã—ãŸã«ã‚‚ã‹ã‹ã‚ã‚‰ãšãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.83\n",
      "Test set score: 0.10\n"
     ]
    }
   ],
   "source": [
    "# ãƒªãƒƒã‚¸å›å¸°\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha = 20).fit(x_train_selected, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(x_train_selected, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(x_test_selected, y_test)))\n",
    "# ã¾ã éå‰°é©åˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(å­¦ç¿’ã«é–¢ã—ã¦ã‚ã‹ã£ãŸã“ã¨)<br/>\n",
    "- ï¼ˆç‰¹å¾´é‡é¸æŠï¼‹ï¼‰ç·šå½¢å›å¸°ã§ã¯è¡¨ã›ãªã„ï¼ˆæ•™å¸«ã‚ã‚Šå­¦ç¿’ã€ç·šå½¢å›å¸°ï¼‰\n",
    "- lassoå›å¸°ã§ã—ã¦ã‚‚ã‚¹ã‚³ã‚¢ã§ãªã„\n",
    "- ä»Šå›ã¯0åˆ—ç›®ã‚’ä½¿ã£ãŸãŒã€åˆ¥ã®å€¤ã‚’ä½¿ã£ãŸã‚‰ç²¾åº¦ãŒä¸ŠãŒã‚‹ã‹ã‚‚ã—ã‚Œãªã„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_selected.shape : (419, 640)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡é¸æŠã‚’ç”¨ã„ãŸçµæœ\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "score = LogisticRegression().fit(x_train_selected, train_scores_encoded).score(x_test_selected, test_scores_encoded)\n",
    "print(f\"x_train_selected.shape : {x_train_selected.shape}\")\n",
    "#print(f'Score with only selected features : {score:.3f}')\n",
    "\n",
    "\n",
    "#score = LogisticRegression().fit(x_train_l1, y_train).score(x_test_selected, y_test)\n",
    "#print(\"Test score: {:.3f}\".format(score))  # 0ã¨å‡ºã‚‹\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Â ç¢ºç‡å ´\n",
    "\n",
    "- ç¢ºç‡å ´$Z$ãŒã‚®ãƒ–ã‚¹çš„ã§ã‚ã‚‹ â‡” ãã®ã¨ãã«ç¢ºç‡å¯†åº¦é–¢æ•°ãŒğŸ‘‡ã¨ãªã£ã¦ã„ã‚‹\n",
    "$$\n",
    "f(z) =  \\frac{e^{-E(z)}}{Z}\n",
    "$$\n",
    "<br/>\n",
    "- ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢æ•°$E$ã‚’ã‚‚ã¤ã‚®ãƒ–ã‚¹åˆ†å¸ƒï¼ˆor ãƒœãƒ«ãƒ„ãƒãƒ³åˆ†å¸ƒï¼‰= ğŸ‘†ã«å¯¾å¿œã—ã¦å®šã¾ã‚‹åˆ†å¸ƒ\n",
    "- $Z$ã¯å®šæ•°\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "### 2. ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢æ•°ã®è¨­å®š\n",
    "- $E()$ã®è¨­å®šâ†’å…ƒç¥–maskãŒä¸€ç•ªå°ã•ããªã‚‹ã‚ˆã†ã«ã€ç›¸äº’æƒ…å ±é‡ã§ã¯maskåŒå£«ãŒä¸€ç•ªå¤§ãããªã‚‹\n",
    "- ç¢ºç‡ã‚’ã©ã†æ›¸ãã‹â†’$f(z)$ã®è¨­å®šã€å®šæ•°ã¯ç„¡è¦–\n",
    "- ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å¤§ãã•æ¯”è¼ƒâ†’æ¯”ã‚’è¨ˆç®—\n",
    "- ä¹±æ•°ç™ºç”Ÿâ†’uniform...\n",
    "- æ¡æŠã€æ£„å´â†’æ›´æ–°ã™ã‚‹ã‹å¦ã‹ã®æ±ºæ–­ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒä¸€ã¤å‰ã®ã‚ˆã‚Šå°ã•ã‹ã£ãŸã‚‰æ¡æŠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = [] #Eã¯é…åˆ—ã€ã©ã‚“ã©ã‚“å…¥ã‚Œã¦ã„ã(ä¸€ã¤å¾Œã‚ã§è¨ˆç®—ã®éš›ä½¿ç”¨ã•ã‚Œã‚‹)\n",
    "def Energy(mask_trial):\n",
    "    return 1-normalized_mutual_info_score(mask_trial, mask) #ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®å®šç¾©â‰¡1-æ¨™æº–åŒ–ç›¸äº’æƒ…å ±é‡ ã¨ã—ãŸ\n",
    "#np.append(E, Energy(mask)) #ç¬¬ä¸€è¦ç´ ã‚’è¿½åŠ \n",
    "E.append(Energy(mask))\n",
    "#print(Energy(mask))\n",
    "#print(mask)\n",
    "print(type(E))\n",
    "print(E[0])\n",
    "\n",
    "\n",
    "#mask_trial ...new_yã«ã‚ˆã£ã¦é¸ã°ã‚ŒãŸå¡©åŸºmask(x)ã€forãƒ«ãƒ¼ãƒ—ã‚’å›ã™ãŸã³å€¤ãŒå¤‰ã‚ã‚‹ã€maskã¨æ¯”è¼ƒã™ã‚‹ãŸã‚ã«ã‚ã‚‹ã ã‘ãªã®ã§ä¿å­˜ã™ã‚‹å¿…è¦ãªã—\n",
    "\n",
    "save_y = [] #ã»ã—ã„ãƒ™ã‚¯ãƒˆãƒ«ã‚’è²¯ã‚ã‚‹é…åˆ—\n",
    "new_y = data_amount #ä»¥é™è¦ç´ ã‚’ä¸€ã¤ãšã¤å¤‰ãˆã¦ã„ã #data_amountã¯Series\n",
    "\n",
    "import math\n",
    "\n",
    "for i in range(1, 100):   \n",
    "    new_y[i] = 1 - new_y[i] #è¦ç´ ä¸€ã¤ã ã‘å¤‰ãˆãŸ\n",
    "    \n",
    "    select = SelectFromModel(RandomForestRegressor(n_estimators = 100, random_state = 42), threshold = 'median', max_features=640)\n",
    "    select.fit(data_SNP, new_y)\n",
    "    data_SNP_l1 = select.transform(data_SNP)\n",
    "    mask_trial = select.get_support()\n",
    "\n",
    "    #np.append(E, Energy(mask_trial))  #mask_trialã¯ä¸€ã¤ã®ndarrayã®ä¸­ã§é †ç•ªã«è¦ç´ ã‚’æ›´æ–°ã—ã¦ã„ã\n",
    "    E.append(Energy(mask_trial))\n",
    "    r = math.exp(-E[i])/math.exp(-E[i-1])\n",
    "    R = np.random.uniform(0.0, 1.0)\n",
    "    if R >= r : #f(z)ãŒä¸€å€‹å‰ã®ã‚‚ã®ã‚ˆã‚Šã‚‚å°ã•ã‹ã£ãŸã‚‰â‡”E[i]ãŒä¸€å€‹å‰ã®ã‚‚ã®ã‚ˆã‚Šã‚‚å¤§ãã‹ã£ãŸã‚‰\n",
    "        new_y[i] =1 - new_y[i] #å…ƒã«æˆ»ã™   \n",
    "    if i%100 == 0:\n",
    "        save_y.append(new_y)\n",
    "    else:\n",
    "            continue\n",
    "    if len(save_y) > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
