{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shihosato/src/github.com/twinkle13531/master_degree/202012/Summary/p_value\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join('..', '..','Random'))\n",
    "sys.path.append(os.path.join('..', '..', 'SA'))\n",
    "sys.path.append(os.path.join('..', '..', 'QA'))\n",
    "sys.path.append(os.path.join('..', '..', '4ti2', 'functions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import QA_DwaveSampler_AutoEmbedding as qda\n",
    "import random_exact_test_functions as ret\n",
    "import Neal_exact_test_functions as net\n",
    "import zsolve_t1 as zt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_dic = {}\n",
    "for bit in [20, 25, 30, 35, 40, 46]:\n",
    "    if bit != 46:\n",
    "        t1_dic[bit] = []\n",
    "        for num in [0, 1, 2, 3, 4]:\n",
    "            df_path = '../../input/ost{}_{}.csv'.format(bit, num)\n",
    "            df = pd.read_csv(df_path, sep=',')\n",
    "            t_list = ret.calc_marginals(df)\n",
    "            t1_dic[bit].append(t_list[1])\n",
    "    else:\n",
    "        df_path = '../../input/ost{}.csv'.format(bit)\n",
    "        df = pd.read_csv(df_path, sep=',')\n",
    "        t_list = ret.calc_marginals(df)\n",
    "        t1_dic[46] = t_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: [8, 11, 10, 7, 7],\n",
       " 25: [10, 8, 9, 13, 11],\n",
       " 30: [12, 8, 14, 12, 12],\n",
       " 35: [13, 14, 14, 15, 14],\n",
       " 40: [16, 16, 15, 18, 16],\n",
       " 46: 19}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exhaustive enumeration\n",
    "### {bit:{num:[valid_y_num, time, pertime, same_t1_y_num, p_value]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enu_time_dic = {}\n",
    "enu_time_dic[20] = [4.94, 0.23, 2.47, 0.13, 0.08]\n",
    "enu_time_dic[25] = [6.26, 1.45, 522.78, 60.29, 4.29]\n",
    "enu_time_dic[30] = [114590.22, 70282.15, 4964.31, 2701.98, 594.18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: [4.94, 0.23, 2.47, 0.13, 0.08],\n",
       " 25: [6.26, 1.45, 522.78, 60.29, 4.29],\n",
       " 30: [114590.22, 70282.15, 4964.31, 2701.98, 594.18]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enu_time_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "enu_valid_y_info_dic = {}\n",
    "for bit in [20, 25, 30]:\n",
    "    enu_valid_y_info_dic[bit] = {}\n",
    "    for num in [0, 1, 2, 3, 4]:\n",
    "        enu_valid_y_info_dic[bit][num] = []\n",
    "        path = \"../../input/ost{}_{}.csv\".format(bit, num)\n",
    "        df = pd.read_csv(path, sep=',')\n",
    "        zinhom_path = '../../4ti2/{}bit/{}/{}bit_{}.zinhom'.format(bit, num, bit, num)\n",
    "        zinhom_num, zinhom_list = zt.make_result_list(zinhom_path)\n",
    "        p, num_sample = zt.calucurate_p(df, zinhom_list)\n",
    "        \n",
    "        enu_valid_y_info_dic[bit][num].append(num_sample)#valid_y_num\n",
    "        enu_valid_y_info_dic[bit][num].append(enu_time_dic[bit][num])\n",
    "        enu_valid_y_info_dic[bit][num].append(enu_time_dic[bit][num]/num_sample)\n",
    "        enu_valid_y_info_dic[bit][num].append(p*num_sample)#same_t1_y_num\n",
    "        enu_valid_y_info_dic[bit][num].append(p)#same_t1_y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: {0: [16464, 4.94, 0.0003000485908649174, 3780.0, 0.22959183673469388],\n",
       "  1: [2940, 0.23, 7.823129251700681e-05, 1225.0, 0.4166666666666667],\n",
       "  2: [1050, 2.47, 0.0023523809523809526, 500.0, 0.47619047619047616],\n",
       "  3: [2640, 0.13, 4.9242424242424245e-05, 1430.0, 0.5416666666666666],\n",
       "  4: [2464, 0.08, 3.246753246753247e-05, 720.0, 0.2922077922077922]},\n",
       " 25: {0: [12600, 6.26, 0.0004968253968253968, 1050.0, 0.08333333333333333],\n",
       "  1: [5850,\n",
       "   1.45,\n",
       "   0.00024786324786324785,\n",
       "   839.9999999999999,\n",
       "   0.14358974358974358],\n",
       "  2: [109010, 522.78, 0.00479570681588845, 10560.0, 0.09687184661957618],\n",
       "  3: [23460, 60.29, 0.002569906223358909, 16560.0, 0.7058823529411765],\n",
       "  4: [1260, 4.29, 0.003404761904761905, 168.0, 0.13333333333333333]},\n",
       " 30: {0: [58296, 114590.22, 1.965661794977357, 2600.0, 0.04459997255386304],\n",
       "  1: [819390, 70282.15, 0.08577374632348454, 11220.0, 0.01369311316955296],\n",
       "  2: [205920, 4964.31, 0.024107954545454547, 35640.0, 0.17307692307692307],\n",
       "  3: [168168, 2701.98, 0.01606714713857571, 17446.0, 0.10374149659863946],\n",
       "  4: [89100, 594.18, 0.006668686868686868, 8580.0, 0.0962962962962963]}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enu_valid_y_info_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random \n",
    "### {bit:{num:[valid_y_num, time, pertime, same_t1_y_num, p_value, num_occurrence, total_valid_y]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 10000\n",
    "random_valid_y_info_dic = {}\n",
    "for bit in [20, 25, 30, 35, 40, 46]:\n",
    "    if bit != 46:\n",
    "        random_valid_y_info_dic[bit] = {}\n",
    "        for num in [0, 1, 2, 3, 4]:\n",
    "            random_valid_y_info_dic[bit][num] = []\n",
    "            df_path = '../../input/ost{}_{}.csv'.format(bit, num)\n",
    "            df = pd.read_csv(df_path, sep=',')\n",
    "            t_list = ret.calc_marginals(df)\n",
    "            valid_y_dic, calculation_time = ret.find_valid_y(df, num_reads)\n",
    "\n",
    "            valid_y_num = len(valid_y_dic)\n",
    "            if valid_y_num > 0:\n",
    "                random_valid_y_info_dic[bit][num].append(valid_y_num)#valid_y_num\n",
    "                random_valid_y_info_dic[bit][num].append(calculation_time)\n",
    "                random_valid_y_info_dic[bit][num].append(calculation_time/len(valid_y_dic))\n",
    "\n",
    "                t1 = t_list[1]\n",
    "                t1_y = 0\n",
    "                for candi_y in list(valid_y_dic.keys()):\n",
    "                    if np.dot(df['LI'], pd.Series(candi_y)) == t1:\n",
    "                        t1_y += 1\n",
    "                random_valid_y_info_dic[bit][num].append(t1_y)#same_t1_y_num\n",
    "                random_valid_y_info_dic[bit][num].append(t1_y/valid_y_num)#same_t1_y_num\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        random_valid_y_info_dic[bit] = []\n",
    "        df_path = '../../input/ost{}.csv'.format(bit)\n",
    "        df = pd.read_csv(df_path, sep=',')\n",
    "        t_list = ret.calc_marginals(df)\n",
    "        valid_y_dic, calculation_time = ret.find_valid_y(df, num_reads)\n",
    "        \n",
    "        valid_y_num = len(valid_y_dic)\n",
    "        if valid_y_num > 0:\n",
    "            random_valid_y_info_dic[bit].append(valid_y_num)#valid_y_num\n",
    "            random_valid_y_info_dic[bit].append(calculation_time)\n",
    "            random_valid_y_info_dic[bit].append(calculation_time/len(valid_y_dic))\n",
    "\n",
    "            t1 = t_list[1]\n",
    "            t1_y = 0\n",
    "            for candi_y in list(valid_y_dic.keys()):\n",
    "                if np.dot(df['LI'], pd.Series(candi_y)) == t1:\n",
    "                    t1_y += 1\n",
    "            random_valid_y_info_dic[bit].append(t1_y)#same_t1_y_num\n",
    "            random_valid_y_info_dic[bit].append(t1_y/valid_y_num)#same_t1_y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: {0: [152,\n",
       "   0.9085249900817871,\n",
       "   0.0059771380926433365,\n",
       "   36,\n",
       "   0.23684210526315788],\n",
       "  1: [25, 0.38257789611816406, 0.015303115844726562, 12, 0.48],\n",
       "  2: [11, 0.3179290294647217, 0.028902639042247425, 4, 0.36363636363636365],\n",
       "  3: [19, 1.074479103088379, 0.056551531741493626, 10, 0.5263157894736842],\n",
       "  4: [23, 0.9098200798034668, 0.039557394774063774, 3, 0.13043478260869565]},\n",
       " 25: {0: [4, 0.46073293685913086, 0.11518323421478271, 0, 0.0],\n",
       "  1: [],\n",
       "  2: [28, 0.904005765914917, 0.032285920211247036, 4, 0.14285714285714285],\n",
       "  3: [8, 0.6662981510162354, 0.08328726887702942, 5, 0.625],\n",
       "  4: [1, 0.3448147773742676, 0.3448147773742676, 0, 0.0]},\n",
       " 30: {0: [],\n",
       "  1: [13, 0.8195061683654785, 0.06303893602811374, 0, 0.0],\n",
       "  2: [4, 0.44954395294189453, 0.11238598823547363, 0, 0.0],\n",
       "  3: [4, 0.5393242835998535, 0.13483107089996338, 0, 0.0],\n",
       "  4: []},\n",
       " 35: {0: [],\n",
       "  1: [4, 0.5745761394500732, 0.1436440348625183, 0, 0.0],\n",
       "  2: [4, 0.43874287605285645, 0.10968571901321411, 0, 0.0],\n",
       "  3: [],\n",
       "  4: []},\n",
       " 40: {0: [],\n",
       "  1: [],\n",
       "  2: [],\n",
       "  3: [2, 0.34435176849365234, 0.17217588424682617, 0, 0.0],\n",
       "  4: []},\n",
       " 46: []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_valid_y_info_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA \n",
    "### {bit:{num:[valid_y_num, time, pertime, same_t1_y_num, p_value, num_occurrence, total_valid_y]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../input/ost46_4.csv does not exist: '../../input/ost46_4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9ae53173b71e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mSA_valid_y_info_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../input/ost{}_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtime_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.7.12/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../input/ost46_4.csv does not exist: '../../input/ost46_4.csv'"
     ]
    }
   ],
   "source": [
    "num_reads = 10000\n",
    "SA_valid_y_info_dic = {}\n",
    "for bit in [20, 25, 30, 35, 40, 46]:\n",
    "    if bit != 46:\n",
    "        SA_valid_y_info_dic[bit] = {}\n",
    "        for num in [0, 1, 2, 3, 4]:\n",
    "            SA_valid_y_info_dic[bit][num] = []\n",
    "            path = '../../input/ost{}_{}.csv'.format(bit, num)\n",
    "            df = pd.read_csv(path, sep=',')\n",
    "\n",
    "            time_0 = time.time()\n",
    "            res = net.make_res_data(df, num_reads)\n",
    "            valid_y_dic = net.find_valid_y(res)\n",
    "            time_1 = time.time()\n",
    "            calculation_time = time_1 - time_0\n",
    "\n",
    "            valid_y_num = len(valid_y_dic)\n",
    "            if valid_y_num > 0:\n",
    "                SA_valid_y_info_dic[bit][num].append(valid_y_num)#valid_y_num\n",
    "                SA_valid_y_info_dic[bit][num].append(calculation_time)\n",
    "                SA_valid_y_info_dic[bit][num].append(calculation_time/len(valid_y_dic))\n",
    "\n",
    "                t1 = np.dot(df['Y'], df['LI'])\n",
    "                t1_y = 0\n",
    "                for candi_y in list(valid_y_dic.keys()):\n",
    "                    if np.dot(df['LI'], pd.Series(candi_y)) == t1:\n",
    "                        t1_y += 1\n",
    "                SA_valid_y_info_dic[bit][num].append(t1_y)#same_t1_y_num\n",
    "                SA_valid_y_info_dic[bit][num].append(t1_y/valid_y_num)#same_t1_y_num\n",
    "    else:\n",
    "        SA_valid_y_info_dic[bit] = []\n",
    "        path = '../../input/ost{}_{}.csv'.format(bit, num)\n",
    "        df = pd.read_csv(path, sep=',')\n",
    "\n",
    "        time_0 = time.time()\n",
    "        res = net.make_res_data(df, num_reads)\n",
    "        valid_y_dic = net.find_valid_y(res)\n",
    "        time_1 = time.time()\n",
    "        calculation_time = time_1 - time_0\n",
    "\n",
    "        valid_y_num = len(valid_y_dic)\n",
    "        if valid_y_num > 0:\n",
    "            SA_valid_y_info_dic[bit].append(valid_y_num)#valid_y_num\n",
    "            SA_valid_y_info_dic[bit].append(calculation_time)\n",
    "            SA_valid_y_info_dic[bit].append(calculation_time/len(valid_y_dic))\n",
    "\n",
    "            t1 = np.dot(df['Y'], df['LI'])\n",
    "            t1_y = 0\n",
    "            for candi_y in list(valid_y_dic.keys()):\n",
    "                if np.dot(df['LI'], pd.Series(candi_y)) == t1:\n",
    "                    t1_y += 1\n",
    "            SA_valid_y_info_dic[bit].append(t1_y)#same_t1_y_num\n",
    "            SA_valid_y_info_dic[bit].append(t1_y/valid_y_num)#same_t1_y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_valid_y_info_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA \n",
    "### {bit:{num:[valid_y_num, time, pertime, same_t1_y_num, p_value, num_occurrence, total_valid_y, chain_strength, broken_percent]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reads = 10000\n",
    "random_valid_y_info_dic = {}\n",
    "for bit in [20, 25, 30, 35, 40]:\n",
    "    \n",
    "    random_valid_y_info_dic[bit] = {}\n",
    "    for num in [0, 1, 2, 3, 4]:\n",
    "        random_valid_y_info_dic[bit][num] = []\n",
    "        df_path = '../input/ost{}_{}.csv'.format(bit, num)\n",
    "        df = pd.read_csv(df_path, sep=',')\n",
    "        t_list = ret.calc_marginals(df)\n",
    "        valid_y_dic, calculation_time = ret.find_valid_y(df, num_reads)\n",
    "        \n",
    "        valid_y_num = len(valid_y_dic)\n",
    "        if valid_y_num > 0:\n",
    "            random_valid_y_info_dic[bit][num].append(valid_y_num)#valid_y_num\n",
    "\n",
    "            t1 = t_list[1]\n",
    "            t1_y = 0\n",
    "            for candi_y in list(valid_y_dic.keys()):\n",
    "                if np.dot(df['LI'], pd.Series(candi_y)) == t1:\n",
    "                    t1_y += 1\n",
    "            random_valid_y_info_dic[bit][num].append(t1_y)#same_t1_y_num\n",
    "            random_valid_y_info_dic[bit][num].append(t1_y/valid_y_num)#same_t1_y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
